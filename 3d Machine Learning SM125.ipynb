{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SM125 Modell y= mm/min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import os\n",
    "from keras.layers import *\n",
    "from keras.activations import *\n",
    "from keras.models import *\n",
    "from keras.optimizers import *\n",
    "from keras.initializers import *\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "sm125x = pd.read_excel(\"http://boehler-edelstahl-intranet/Arbeitswirtschaft/RPA/SM125.xlsx\", sheet_name='6 Spalten')\n",
    "sm125m = pd.read_excel(\"http://boehler-edelstahl-intranet/Arbeitswirtschaft/RPA/SM125.xlsx\", sheet_name='Marken')\n",
    "\n",
    "df = pd.DataFrame(sm125x)\n",
    "df_m = pd.DataFrame(sm125m)\n",
    "\n",
    "np_data = np.array(df)\n",
    "np_m = np.array(df_m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Info Ausgabe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4316 entries, 0 to 4315\n",
      "Data columns (total 13 columns):\n",
      "Marke                     4316 non-null object\n",
      "Marke(4)                  4316 non-null object\n",
      "Aufmass (rechn.)          4316 non-null float64\n",
      "Durchmesser               4316 non-null float64\n",
      "Fabrikat                  4316 non-null int64\n",
      "cm/min                    4316 non-null float64\n",
      "Schällänge [m]            4316 non-null float64\n",
      "Bearbeitungszeit [min]    4316 non-null float64\n",
      "Unnamed: 8                1 non-null float64\n",
      "0                         4316 non-null float64\n",
      "Unnamed: 10               4316 non-null float64\n",
      "0.1                       4316 non-null float64\n",
      "Unnamed: 12               4316 non-null float64\n",
      "dtypes: float64(10), int64(1), object(2)\n",
      "memory usage: 438.4+ KB\n",
      "None\n",
      "(4316, 13)\n",
      "['L150' 'L150' 'L150' ... 'K720' 'W360' 'W360']\n",
      "(4316, 13)\n",
      "(148, 1)\n"
     ]
    }
   ],
   "source": [
    "print(sm125x.info())\n",
    "print(sm125x.shape)\n",
    "x = np.array(sm125x)\n",
    "print(x[:,1])\n",
    "\n",
    "print(df.shape)\n",
    "print(df_m.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Versuch:\n",
    "### Marken ausgeben"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['L150' 'L140' 'L135' 'L314' 'L331' 'L372' 'L330' 'L343' 'L334' 'L328'\n",
      " 'L333' 'A913' 'T200' 'T504' 'A911' 'S903' 'N701' 'A903' 'L321' 'P511'\n",
      " 'S692' 'N709' 'S790' 'M264' 'S392' 'L392' 'N721' 'T560' 'S592' 'K497'\n",
      " 'A926' 'P513' 'N700' 'K890' 'K294' 'T552' 'K600' 'H500' 'S290' 'V118'\n",
      " 'V354' 'T671' 'S690' 'S390' 'M303' 'S590' 'T505' 'R250' 'K390' 'A961'\n",
      " 'M315' 'K330' 'C599' 'T670' 'N400' 'E108' 'V723' 'V145' 'M340' 'A750'\n",
      " 'W722' 'N695' 'N352' 'M390' 'V141' 'S693' 'V124' 'K107' 'W720' 'P501'\n",
      " 'N690' 'M261' 'M238' 'K135' 'M461' 'R675' 'M310' 'R100' 'S705' 'G459'\n",
      " 'S600' 'M121' 'A965' 'T550' 'C657' 'M368' 'N360' 'C600' 'H525' 'M300'\n",
      " 'M333' 'K110' 'K490' 'K105' 'S376' 'C712' 'K550' 'V726' 'K360' 'S500'\n",
      " 'N717' 'P504' 'R615' 'W303' 'W300' 'K340' 'N685' 'M130' 'C647' 'W360'\n",
      " 'M314' 'W302' 'W320' 'K100' 'P570' 'K455' 'W460' 'E101' 'S393' 'K190'\n",
      " 'A220' 'V361' 'T262' 'K460' 'W403' 'K305' 'K698' 'K313' 'S405' 'K605'\n",
      " 'S400' 'W307' 'K353' 'M200' 'P536' 'S401' 'V720' 'K720' 'A405' 'K245'\n",
      " 'T651' 'W400' 'A400' 'P550' 'N530' 'S630' 'S200' 'W100']\n"
     ]
    }
   ],
   "source": [
    "zahl1 = 5.89\n",
    "zahl2 = 78.67\n",
    "    \n",
    "x_zahl = [zahl1, zahl2]\n",
    "x_text_cat = 1\n",
    "x_text_cat_onehot = tf.keras.utils.to_categorical(x_text_cat, num_classes=2)\n",
    "x = np.concatenate((x_zahl, x_text_cat_onehot))\n",
    "     \n",
    "#x = ( [zahl1, zahl2, 0, 1])\n",
    "   \n",
    "#x_train = np.array([ [tf.keras.utils.to_categorical(np_m[0]), np_m[1:]] for np_m in x_train])\n",
    "    \n",
    "#x_text_marken_cat_onehot = tf.keras.utils.to_categorical(np_m[:,0], num_classes=148)\n",
    "    \n",
    "print(np_m[:,0])\n",
    "# np.save('I:/RPA/SM125.npy', np_m[:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daten aufbereiten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = []\n",
    "x_data_marke =[]\n",
    "y_data = []\n",
    "                    \n",
    "for i in range(len(np_data)):\n",
    "    # print(np_data[i,1] , np.where(np_m[:,0]==np_data[i,1])[0][0] , np_data[i,2]      )\n",
    "    # print(i)\n",
    "    marke2zahl = np.where(np_m[:,0]==np_data[i,1])[0][0]\n",
    "    x_data_marke.append([marke2zahl])\n",
    "    y_data.append(np_data[i,5] )\n",
    "    \n",
    "x_data_marke_onehot = tf.keras.utils.to_categorical(x_data_marke, num_classes=150)     \n",
    "\n",
    "for z in range(len(np_data)):\n",
    "    x_zeile =[]\n",
    "    for i in range(150):\n",
    "        x_zeile.append(x_data_marke_onehot[z,i])\n",
    "    x_zeile.append(np_data[z,2])\n",
    "    x_zeile.append(np_data[z,3])\n",
    "    x_data.append(x_zeile)\n",
    "\n",
    "x_data = np.array(x_data)  \n",
    "y_data = np.array(y_data) \n",
    "\n",
    "#print(x_data.shape)\n",
    "#print(y_data.shape)\n",
    "\n",
    "# print(y_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modell trainieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train,  x_test, y_train, y_test = np.array([[0,0],[0,0]]),np.array([0]),np.array([[0,0]]),np.array([0]),\n",
    "# x_train, y_train, x_test, y_test = x_data, y_data, x_data, y_data\n",
    "\n",
    "x_train, x_test, y_train,  y_test = train_test_split(x_data, y_data, test_size=0.2)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "\n",
    "num_features = 152\n",
    "train_size, test_size = x_train.shape[0], x_test.shape[0]\n",
    "\n",
    "init_w = RandomUniform(minval=0.0, maxval=2.0)\n",
    "init_b = Constant(value=0.0)\n",
    "\n",
    "# Define the DNN\n",
    "model = Sequential()\n",
    "model.add(Dense(152, kernel_initializer=init_w, bias_initializer=init_b, input_shape=(num_features,)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dense(1, kernel_initializer=init_w, bias_initializer=init_b))\n",
    "model.summary()\n",
    "\n",
    "def r_squared(y_true, y_pred):\n",
    "    numerator = tf.reduce_mean(tf.square(tf.subtract(y_true, y_pred)))\n",
    "    denominator = tf.reduce_mean(tf.square(tf.subtract(y_true, tf.reduce_mean(y_true))))\n",
    "    r2 = tf.clip_by_value(tf.subtract(1.0, tf.div(numerator, denominator)), clip_value_min=0.0, clip_value_max=1.0)\n",
    "    return r2\n",
    "\n",
    "# Train the DNN\n",
    "lr = 0.005\n",
    "optimizer = Adam(lr=lr)\n",
    "\n",
    "model.compile(\n",
    "    loss=\"mse\",\n",
    "    optimizer=optimizer,\n",
    "    metrics=[r_squared])\n",
    "\n",
    "model.fit(\n",
    "    x=x_train,\n",
    "    y=y_train,\n",
    "    verbose=1,\n",
    "    batch_size=128,\n",
    "    epochs=1000,\n",
    "    validation_data=[x_test, y_test] )\n",
    "\n",
    "# Test the DNN\n",
    "score = model.evaluate(x_test, y_test)\n",
    "print(\"Score: \", score)\n",
    "\n",
    "model.save_weights(filepath=\"I:/RPA/sm125_pred.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gewichte einlesen und neue Planzeiten ermitteln\n",
    "### Ergebnisse in Excel speichern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_59 (Dense)             (None, 152)               23256     \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 152)               0         \n",
      "_________________________________________________________________\n",
      "dense_60 (Dense)             (None, 1)                 153       \n",
      "=================================================================\n",
      "Total params: 23,409\n",
      "Trainable params: 23,409\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "[[ -6.6100283]\n",
      " [ -9.617658 ]\n",
      " [ -3.9364898]\n",
      " ...\n",
      " [634.68207  ]\n",
      " [474.6317   ]\n",
      " [474.6317   ]]\n"
     ]
    }
   ],
   "source": [
    "#x_train, x_test, y_train,  y_test = train_test_split(x_data, y_data, test_size=0.2)\n",
    "#print(x_train[0,:])\n",
    "#print( x_train[0,:].shape)\n",
    "\n",
    "\n",
    "num_features = 152\n",
    "init_w = Constant(value=0.0)\n",
    "init_b = Constant(value=0.0)\n",
    "\n",
    "# Define the DNN\n",
    "model = Sequential()\n",
    "model.add(Dense(152, kernel_initializer=init_w, bias_initializer=init_b, input_shape=(num_features,)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dense(1, kernel_initializer=init_w, bias_initializer=init_b))\n",
    "model.summary()\n",
    "\n",
    "model.compile(\n",
    "    loss=\"mse\",\n",
    "    optimizer=optimizer,\n",
    "    metrics=[r_squared])\n",
    "\n",
    "# Gewichte laden\n",
    "model.load_weights(\"I:/RPA/sm125_pred.h5\")\n",
    "# y_pred = model.predict(x_data[[10]])\n",
    "y_pred = model.predict(x_data)\n",
    "\n",
    "print(y_pred)\n",
    "\n",
    "df = pd.DataFrame(y_pred)\n",
    "# Create a Pandas Excel writer using XlsxWriter as the engine.\n",
    "xwriter = pd.ExcelWriter('I:/RPA/sm125_pred.xlsx', engine='xlsxwriter')\n",
    "# Convert the dataframe to an XlsxWriter Excel object.\n",
    "df.to_excel(xwriter, sheet_name='Sheet1')\n",
    "# Close the Pandas Excel writer and output the Excel file.\n",
    "xwriter.save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
